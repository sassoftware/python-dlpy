{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SAS DLPy to Define SAS Viya Model Learning Rate Policies\n",
    "\n",
    "When training deep learning neural network models, a suitable learning rate policy is ofen essential for good performance.  This example notebook demonstrates how you can use SAS DLPy to specify different predefined learning rate policies for your SAS Viya deep learning models. This notebook also shows you how to specify your own customized learning rate policy using the SAS Viya FCMP function utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Important Note: Client and Server Definitions](#ClientServer)\n",
    "- [Prepare Resources and Configure Computing Environment for Modeling](#getReady)\n",
    "    - [Download the Image Data](#downloadData)\n",
    "    - [Import Required Python and SAS DLPy Modules](#importPythonDLPy)\n",
    "- [Launch SAS CAS Session](#LaunchCAS)\n",
    "- [Use SAS DLPy to Create a Simple SAS Viya ResNet Network](#CreateResNet)\n",
    "- [Load the Image Data into SAS CAS](#LoadImageData)\n",
    "- [Define the Model Learning Rate Hyperparameter](#DefineLR)\n",
    "    - [Specify Step Learning Rate](#StepLR)\n",
    "    - [Specify Cyclic Learning Rate Scheduler](#CyclicLR)\n",
    "    - [Specify Reduce Learning Rate on Plateau](#ReduceLR_Plat)\n",
    "    - [Specify Customized Learning Rate Policy](#CustomLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ClientServer\"></a>\n",
    "\n",
    "### Important Note: Client and Server Definitions\n",
    "SAS Viya literature and technical documentation often refers to client and server entities. In this scenario, the client is the computer that runs the Jupyter notebook with the example code. The server is the computer that is running the Viya server. These two computers might (or might not) use the same operating system, and might (or might not) have access to a common file system.\n",
    "\n",
    "This notebook assumes that the client and server do not use the same operating system, but that they do have access to a common file system. If the client and server in your environment do not have access to a common file system, you will need to copy or transfer files between client and server during this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines path variables that contain path specifications to  \n",
    "# the client and server model files and image root directories.\n",
    "\n",
    "# Server Learning Rate root location (your path will be different)\n",
    "server_learning_rate_root = r'/your/path/to/Learning_Rate/'\n",
    "\n",
    "# Server Learning Rate Image root location (your path will be different)\n",
    "server_image_root = r'/your/path/to/Learning_Rate/Giraffe_Dolphin' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getReady\"></a>\n",
    "\n",
    "### Prepare Resources and Configure Computing Environment for Modeling\n",
    "\n",
    "Use this section to organize all of the resources that you will need and configure your local computing environment for this notebook example. Performing these tasks in advance means you can run the example without multiple stops to locate and download necessary resources. This approach enables you to focus on how to use SAS DLPy to complete the modeling task in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"downloadData\"></a>\n",
    "\n",
    "#### Download the Image Data\n",
    "\n",
    "All of the examples use a small toy data set that contains dolphin or giraffe images for the classification tasks. You can download the dolphin and giraffe image data from the SAS DLPy GitHub site [here.](https://github.com/sassoftware/python-dlpy/tree/master/dlpy/tests/datasources/giraffe_dolphin_small). Create a folder named `Giraffe_Dolphin` in the server location that you saved as `server_image_root`, and use this folder to contain the `Dolphin` and `Giraffe` image subfolders. The notebook example expects the following folder structures:\n",
    "\n",
    "server_learning_rate_root\n",
    " * Giraffe_Dolphin  (server_image_root)     \n",
    "       * Dolphin\n",
    "           * Dolphin image 1\n",
    "           * Dolphin image 2\n",
    "           * ...  \n",
    "       * Giraffe\n",
    "           * Giraffe image 1\n",
    "           * Giraffe image 2\n",
    "           * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"importPythonDLPy\"></a>\n",
    "\n",
    "#### Import Required Python and SAS DLPy Modules\n",
    "\n",
    "After copying the input image data to your server, configure your client computing environment for image captioning modeling using Python and SAS DLPy. \n",
    "\n",
    "Import the various Python and SAS DLPy modules that this notebook uses. Begin by importing the SAS Scripting Wrapper for Analytic Transfer (SWAT). SWAT is the Python interface to SAS CAS. You can find more detailed information about starting a SAS CAS session with the SWAT package [here](https://sassoftware.github.io/python-swat/getting-started.html). \n",
    "\n",
    "Import the SAS DLPy modules and functions that are used to create the CNN and RNN models in this notebook. The DLPy `ImageTable` module makes it easier to load images from a folder into a SAS CAS table. The DLPy `applications` module contains parameters for the pre-built VGG-16 CNN model that the notebook uses to perform image feature extraction.\n",
    "\n",
    "The `image_captioning` module contains the functions that are necessary for building the RNN image captioning model and to create the captioned image table that will be used for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python utilities \n",
    "# and SAS DLPy modules\n",
    "\n",
    "import swat\n",
    "import sys\n",
    "import dlpy\n",
    "from dlpy.layers import *\n",
    "from dlpy.model import *\n",
    "from dlpy.images import ImageTable\n",
    "from dlpy.sequential import Sequential\n",
    "from dlpy.lr_scheduler import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LaunchCAS\"></a>\n",
    "\n",
    "### Launch SAS CAS Session\n",
    "\n",
    "SAS DLPy requires a running SAS CAS server and the SAS Scripting Wrapper for Analytic Transfer (SWAT). The SWAT package is a Python interface to CAS. You can choose the port number you want to use. By default SAS uses '5570' for a portID. \n",
    "\n",
    "Note: For more information about starting a CAS session with the SWAT package, see https://sassoftware.github.io/python-swat/getting-started.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch SAS CAS session\n",
    "host_name='your-server.unx.your-company.com'\n",
    "port_number='5570'\n",
    "\n",
    "sess = swat.CAS(host_name, port_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CreateResNet\"></a>\n",
    "\n",
    "### Use SAS DLPy to Create a Simple SAS Viya ResNet Network\n",
    "\n",
    "ResNet models are a family of models that were developed as backbones for convolutional neural networks performing computer vision tasks, such as image classification. The SAS DLPy API includes complete ResNet model architectures, but you can also use DLPy to define a simple ResNet model from scratch at the block level.\n",
    "\n",
    "The following code uses SAS DLPy to create a simple ResNet CNN model named `resnet_like_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define convolution blocks\n",
    "\n",
    "def conv_block(x, filters, size, stride=1, mode='same', act=True):\n",
    "    x = Conv2d(filters, size, size, act='identity', include_bias=False, stride=stride)(x)\n",
    "    x = BN(act='relu' if act else 'identity')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define residual blocks\n",
    "\n",
    "def res_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, 2)\n",
    "    x = conv_block(x, nf, 3, 1, act=False)\n",
    "    return Res()([x, ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define input layer, shape, and scale\n",
    "inp_resnet= Input(3, 112, 112, scale = 1.0 / 255, name='InputLayer_1')\n",
    "\n",
    "# 2D Convolution and Pooling layers\n",
    "x=conv_block(inp_resnet, 64, 9, 1)\n",
    "for i in range(4): x=res_block(x)\n",
    "x=Conv2d(20, 9, 9, act='tanh')(x)\n",
    "x=Pooling(7, 7)(x)\n",
    "\n",
    "# Output layer\n",
    "output = OutputLayer(n=2)(x)\n",
    "\n",
    "# Name and compile the model \n",
    "resnet_like_model = Model(sess, inputs = inp_resnet, outputs = output)\n",
    "resnet_like_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to visualize `resnet_like_model`, un-comment and run the `plot_network()` line below to display a DAG of the newly-created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dislpay a DAG of the new model (optional)\n",
    "\n",
    "# resnet_like_model.plot_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadImageData\"></a>\n",
    "\n",
    "### Load the Image Data into SAS CAS\n",
    "\n",
    "This step loads the server-side Giraffe and Dolphin image data that you downloaded from GitHub and saved under `server_image_root` into SAS CAS as a table named `my_images`. All of the images in the table are resized to uniform dimensions of 112 px by 112 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the image path stored in server_image_root \n",
    "img_path = server_image_root\n",
    "\n",
    "# Load the files in the image path to table my_images\n",
    "my_images = ImageTable.load_files(sess, path=img_path)\n",
    "\n",
    "# Resize all images to 112 px by 112 px\n",
    "my_images.resize(112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DefineLR\"></a>\n",
    "\n",
    "### Define the Model Learning Rate Hyperparameter\n",
    "\n",
    "The example thus far has used SAS DLPy to create a simple ResNet image classification model and created a 112 x 112 input image table in SAS CAS. Now it is time to consider how to define the best learning rate for this neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAS DLPy API includes a choice of predefined learning rate policies you can specify:\n",
    "\n",
    "- FixedLR\n",
    "- StepLR\n",
    "- MultiStepLR\n",
    "- PolynomialLR\n",
    "- ReduceLROnPlateau\n",
    "- CyclicLR\n",
    "\n",
    "SAS DLPy also allows you to create your own custom learning rate policy using the SAS FCMP function compiling procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"StepLR\"></a>\n",
    "\n",
    "#### Specify a Step Learning Rate\n",
    "\n",
    "The following code uses SAS DLPy to specify and configure step learning rate `StepLR` hyperparameters for the model `resnet_like_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following argument(s) learning_rate, learning_rate_policy, gamma, step_size, power are overwritten by the according arguments specified in lr_scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Specify Step Learn Rate parameters\n",
    "lr_scheduler = StepLR(learning_rate=0.0001, \n",
    "                      gamma=0.1, \n",
    "                      step_size=2\n",
    "                     )\n",
    "\n",
    "# Momentum solver using StepLR \n",
    "solver = MomentumSolver(lr_scheduler=lr_scheduler, \n",
    "                        clip_grad_max = 100, \n",
    "                        clip_grad_min = -100\n",
    "                       )\n",
    "\n",
    "# Optimizer and GPU settings\n",
    "optimizer = Optimizer(algorithm=solver, \n",
    "                      mini_batch_size=16, \n",
    "                      log_level=3, \n",
    "                      max_epochs=50, \n",
    "                      reg_l2=0.0005\n",
    "                     )\n",
    "\n",
    "gpu = Gpu(devices=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the SAS DLPy `fit()` function to train the model `resnet_like_model` with the specified hyperparameter settings and the input data in CAS table `my_images`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Inputs=_image_ is used\n",
      "NOTE: Training from scratch.\n",
      "NOTE: Using your-server.unx.your-company.com: 1 out of 2 available GPU devices.\n",
      "NOTE:  Synchronous mode is enabled.\n",
      "NOTE:  The total number of parameters is 415358.\n",
      "NOTE:  The approximate memory cost is 115.00 MB.\n",
      "NOTE:  Loading weights cost       0.00 (s).\n",
      "NOTE:  Initializing each layer cost       3.23 (s).\n",
      "NOTE:  The total number of threads on each worker is 4.\n",
      "NOTE:  The total mini-batch size per thread on each worker is 16.\n",
      "NOTE:  The maximum mini-batch size across all workers for the synchronous mode is 64.\n",
      "NOTE:  Target variable: _label_\n",
      "NOTE:  Number of levels for the target variable:      2\n",
      "NOTE:  Levels for the target variable:\n",
      "NOTE:  Level      0: Dolphin\n",
      "NOTE:  Level      1: Giraffe\n",
      "NOTE:  Number of input variables:     1\n",
      "NOTE:  Number of numeric input variables:      1\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64   0.0001           0.6887     0.4219     0.2985     0.84\n",
      "NOTE:      1    64   0.0001           0.7914     0.5781     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  0        0.0001            0.74        0.5     0.89\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64   0.0001           0.7217     0.4688     0.2985     0.05\n",
      "NOTE:      1    64   0.0001           0.6987     0.4375     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  1        0.0001          0.7102     0.4531     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00001           0.7181     0.4688     0.2985     0.05\n",
      "NOTE:      1    64  0.00001           0.8379     0.6406     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  2          1E-5           0.778     0.5547     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00001           0.7849     0.5625     0.2985     0.05\n",
      "NOTE:      1    64  0.00001            0.741        0.5     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  3          1E-5           0.763     0.5313     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     1E-6           0.7593     0.5313     0.2985     0.05\n",
      "NOTE:      1    64     1E-6           0.7731     0.5469     0.2985     0.04\n",
      " . . . \n",
      " . . . \n",
      " . . . \n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  47        1E-27          0.7817     0.5703     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64    1E-28           0.7534     0.5313     0.2985     0.05\n",
      "NOTE:      1    64    1E-28           0.7373        0.5     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  48        1E-28          0.7454     0.5156     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64    1E-28           0.6593     0.3906     0.2985     0.05\n",
      "NOTE:      1    64    1E-28           0.7992     0.5938     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  49        1E-28          0.7293     0.4922     0.09\n",
      "NOTE:  The optimization reached the maximum number of epochs.\n",
      "NOTE:  The total time is       5.36 (s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Name</td>\n",
       "      <td>model_6tp7ew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Type</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of Layers</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Input Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of Output Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of Convolutional Layers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Pooling Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Fully Connected Layers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Batch Normalization Layers</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of Residual Layers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of Weight Parameters</td>\n",
       "      <td>414184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Number of Bias Parameters</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total Number of Model Parameters</td>\n",
       "      <td>415358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Approximate Memory Cost for Training (MB)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OptIterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch\">Epoch</th>\n",
       "      <th title=\"LearningRate\">LearningRate</th>\n",
       "      <th title=\"Loss\">Loss</th>\n",
       "      <th title=\"FitError\">FitError</th>\n",
       "      <th title=\"L2Norm\">L2Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.740042</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.710223</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.298460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.777975</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.298460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>1.000000e-27</td>\n",
       "      <td>0.781729</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.298457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>1.000000e-28</td>\n",
       "      <td>0.745350</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.298457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>1.000000e-28</td>\n",
       "      <td>0.729267</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.298457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(UserID)</td>\n",
       "      <td>Model_6TP7eW_weights</td>\n",
       "      <td>416510</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('Model_6TP7eW_weights', caslib='CASUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 9.24s</span> &#183; <span class=\"cas-user\">user 5.75s</span> &#183; <span class=\"cas-sys\">sys 2.51s</span> &#183; <span class=\"cas-memory\">mem 132MB</span></small></p>"
      ],
      "text/plain": [
       "[ModelInfo]\n",
       "\n",
       "                                         Descr                         Value\n",
       " 0                                  Model Name                  model_6tp7ew\n",
       " 1                                  Model Type  Convolutional Neural Network\n",
       " 2                            Number of Layers                            26\n",
       " 3                      Number of Input Layers                             1\n",
       " 4                     Number of Output Layers                             1\n",
       " 5              Number of Convolutional Layers                            10\n",
       " 6                    Number of Pooling Layers                             1\n",
       " 7            Number of Fully Connected Layers                             0\n",
       " 8        Number of Batch Normalization Layers                             9\n",
       " 9                   Number of Residual Layers                             4\n",
       " 10                Number of Weight Parameters                        414184\n",
       " 11                  Number of Bias Parameters                          1174\n",
       " 12           Total Number of Model Parameters                        415358\n",
       " 13  Approximate Memory Cost for Training (MB)                           115\n",
       "\n",
       "[OptIterHistory]\n",
       "\n",
       "     Epoch  LearningRate      Loss  FitError    L2Norm\n",
       " 0       1  1.000000e-04  0.740042  0.500000  0.298460\n",
       " 1       2  1.000000e-04  0.710223  0.453125  0.298460\n",
       " 2       3  1.000000e-05  0.777975  0.554688  0.298460\n",
       " 3       4  1.000000e-05  0.762976  0.531250  0.298459\n",
       " .       .  .             .         .         . \n",
       " .       .  .             .         .         . \n",
       " .       .  .             .         .         . \n",
       " 47     48  1.000000e-27  0.781729  0.570312  0.298457\n",
       " 48     49  1.000000e-28  0.745350  0.515625  0.298457\n",
       " 49     50  1.000000e-28  0.729267  0.492188  0.298457\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                  Name    Rows  Columns  \\\n",
       " 0  CASUSER(UserID)  Model_6TP7eW_weights  416510        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('Model_6TP7eW_weights', caslib='CASUS...  \n",
       "\n",
       "+ Elapsed: 9.24s, user: 5.75s, sys: 2.51s, mem: 132mb"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model \n",
    "resnet_like_model.fit(data=my_images, \n",
    "                      n_threads=4, \n",
    "                      record_seed=13309, \n",
    "                      optimizer=optimizer,\n",
    "                      gpu=gpu, \n",
    "                      log_level=2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model `resnet_like_model` when trained with a `StepLR` learning rate policy, has a final learning rate of 1.000 e-28, a loss value of 0.729267 and a fit error of 0.492188. We can compare these statistics to those of other versions of this model that use different learning rate policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CyclicLR\"></a>\n",
    "\n",
    "#### Specify Cyclic Learning Rate Scheduler\n",
    "\n",
    "\n",
    "The following code uses SAS DLPy to specify and configure cyclic learning rate `CyclicLR` hyperparameters for the model `resnet_like_model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following argument(s) learning_rate, gamma, step_size, power are overwritten by the according arguments specified in lr_scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Specify Cyclic Learn Rate parameters\n",
    "lr_scheduler = CyclicLR(conn=sess, \n",
    "                        data=my_images, \n",
    "                        max_lr=0.01, \n",
    "                        batch_size=1, \n",
    "                        factor=2,\n",
    "                        learning_rate=0.0001\n",
    "                       )\n",
    "\n",
    "# Momentum solver using CyclicLR \n",
    "solver = MomentumSolver(lr_scheduler = lr_scheduler,\n",
    "                        clip_grad_max = 100, \n",
    "                        clip_grad_min = -100\n",
    "                       )\n",
    "\n",
    "# Optimizer and GPU settings\n",
    "optimizer = Optimizer(algorithm=solver, \n",
    "                      mini_batch_size=16, \n",
    "                      log_level=3, \n",
    "                      max_epochs=50, \n",
    "                      reg_l2=0.0005\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the SAS DLPy `fit()` function to train the model `resnet_like_model` with the specified hyperparameter settings and the input data in CAS table `my_images`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Inputs=_image_ is used\n",
      "NOTE: Training based on existing weights.\n",
      "NOTE: Using your-server.unx.your-company.com: 1 out of 2 available GPU devices.\n",
      "NOTE:  Synchronous mode is enabled.\n",
      "NOTE:  The total number of parameters is 415358.\n",
      "NOTE:  The approximate memory cost is 115.00 MB.\n",
      "NOTE:  Loading weights cost       0.00 (s).\n",
      "NOTE:  Initializing each layer cost       0.94 (s).\n",
      "NOTE:  The total number of threads on each worker is 4.\n",
      "NOTE:  The total mini-batch size per thread on each worker is 16.\n",
      "NOTE:  The maximum mini-batch size across all workers for the synchronous mode is 64.\n",
      "NOTE:  Target variable: _label_\n",
      "NOTE:  Number of levels for the target variable:      2\n",
      "NOTE:  Levels for the target variable:\n",
      "NOTE:  Level      0: Dolphin\n",
      "NOTE:  Level      1: Giraffe\n",
      "NOTE:  Number of input variables:     1\n",
      "NOTE:  Number of numeric input variables:      1\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64   0.0001           0.6846     0.4219     0.2985     0.84\n",
      "NOTE:      1    64 0.000153            0.782     0.5781     0.2985     0.05\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  0        0.0002          0.7333        0.5     0.88\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00505           0.7163     0.4688     0.2985     0.05\n",
      "NOTE:      1    64 0.005103           0.6938     0.4375     0.2985     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  1        0.0051           0.705     0.4531     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01           0.7074     0.4688     0.2985     0.05\n",
      "NOTE:      1    64 0.009947           0.8005     0.6406     0.2984     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  2        0.0099           0.754     0.5547     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00505           0.7139     0.5469     0.2984     0.05\n",
      "NOTE:      1    64 0.004997           0.6383     0.2813     0.2984     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  3         0.005          0.6761     0.4141     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64   0.0001           0.6049       0.25     0.2984     0.05\n",
      "NOTE:      1    64 0.000153           0.5779     0.4375     0.2984     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  4        0.0002          0.5914     0.3438     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00505           0.5763        0.5     0.2984     0.05\n",
      "NOTE:      1    64 0.005103           0.5772        0.5     0.2984     0.04\n",
      " . . . \n",
      " . . . \n",
      " . . . \n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  46       0.0099        0.004307          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00505         0.004359          0     0.2967     0.05\n",
      "NOTE:      1    64 0.004997         0.004676          0     0.2966     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  47        0.005        0.004518          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64   0.0001         0.004726          0     0.2966     0.05\n",
      "NOTE:      1    64 0.000153         0.004461          0     0.2966     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  48       0.0002        0.004593          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64  0.00505         0.007837          0     0.2965     0.05\n",
      "NOTE:      1    64 0.005103           0.0056          0     0.2965     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  49       0.0051        0.006719          0     0.09\n",
      "NOTE:  The optimization reached the maximum number of epochs.\n",
      "NOTE:  The total time is       5.40 (s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Name</td>\n",
       "      <td>model_6tp7ew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Type</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of Layers</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Input Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of Output Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of Convolutional Layers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Pooling Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Fully Connected Layers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Batch Normalization Layers</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of Residual Layers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of Weight Parameters</td>\n",
       "      <td>414184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Number of Bias Parameters</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total Number of Model Parameters</td>\n",
       "      <td>415358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Approximate Memory Cost for Training (MB)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OptIterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch\">Epoch</th>\n",
       "      <th title=\"LearningRate\">LearningRate</th>\n",
       "      <th title=\"Loss\">Loss</th>\n",
       "      <th title=\"FitError\">FitError</th>\n",
       "      <th title=\"L2Norm\">L2Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.298457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.705038</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.298457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.753957</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.298450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.676078</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.298424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>97</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>98</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(UserID)</td>\n",
       "      <td>Model_6TP7eW_weights</td>\n",
       "      <td>416510</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('Model_6TP7eW_weights', caslib='CASUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 6.99s</span> &#183; <span class=\"cas-user\">user 6.02s</span> &#183; <span class=\"cas-sys\">sys 2.2s</span> &#183; <span class=\"cas-memory\">mem 132MB</span></small></p>"
      ],
      "text/plain": [
       "[ModelInfo]\n",
       "\n",
       "                                         Descr                         Value\n",
       " 0                                  Model Name                  model_6tp7ew\n",
       " 1                                  Model Type  Convolutional Neural Network\n",
       " 2                            Number of Layers                            26\n",
       " 3                      Number of Input Layers                             1\n",
       " 4                     Number of Output Layers                             1\n",
       " 5              Number of Convolutional Layers                            10\n",
       " 6                    Number of Pooling Layers                             1\n",
       " 7            Number of Fully Connected Layers                             0\n",
       " 8        Number of Batch Normalization Layers                             9\n",
       " 9                   Number of Residual Layers                             4\n",
       " 10                Number of Weight Parameters                        414184\n",
       " 11                  Number of Bias Parameters                          1174\n",
       " 12           Total Number of Model Parameters                        415358\n",
       " 13  Approximate Memory Cost for Training (MB)                           115\n",
       "\n",
       "[OptIterHistory]\n",
       "\n",
       "     Epoch  LearningRate      Loss  FitError    L2Norm\n",
       " 0      51      0.000153  0.733308  0.500000  0.298457\n",
       " 1      52      0.005103  0.705038  0.453125  0.298457\n",
       " 2      53      0.009947  0.753957  0.554688  0.298450\n",
       " 3      54      0.004997  0.676078  0.414062  0.298424\n",
       " .      .       .         .         .         . \n",
       " .      .       .         .         .         . \n",
       " .      .       .         .         .         . \n",
       " 46     97      0.009947  0.004307  0.000000  0.296711\n",
       " 47     98      0.004997  0.004518  0.000000  0.296654\n",
       " 48     99      0.000153  0.004593  0.000000  0.296591\n",
       " 49    100      0.005103  0.006719  0.000000  0.296535\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                  Name    Rows  Columns  \\\n",
       " 0  CASUSER(UserID)  Model_6TP7eW_weights  416510        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('Model_6TP7eW_weights', caslib='CASUS...  \n",
       "\n",
       "+ Elapsed: 6.99s, user: 6.02s, sys: 2.2s, mem: 132mb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "resnet_like_model.fit(data=my_images, \n",
    "                      n_threads=4, \n",
    "                      record_seed=13309, \n",
    "                      optimizer=optimizer,\n",
    "                      gpu=gpu, \n",
    "                      log_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model `resnet_like_model` when trained with a `CyclicLR` learning rate policy, has a final learning rate of 0.005103, a loss value of 0.006719, and a fit error of 0.00.  By comparision, the same model trained using the `StepLR` learning rate policy had a final learning rate of 1.0 e-28, a loss value of 0.729267, and a fit error of 0.492188.\n",
    "\n",
    "When you compare the fit and error statistics, the `resnet_like_model` that was trained using the `CyclicLR` learning rate policy outperforms the model that was trained using the `StepLR` learning rate policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ReduceLR_Plat\"></a>\n",
    "\n",
    "#### Specify Reduce Learning Rate on Plateau\n",
    "\n",
    "The following code uses SAS DLPy to specify and configure the reduce learning rate on plateau `ReduceLROnPlateau` hyperparameters for the model `resnet_like_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following argument(s) learning_rate, gamma, step_size, power are overwritten by the according arguments specified in lr_scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Specify ReduceLROnPlateau hyperparameter settings\n",
    "lr_scheduler = ReduceLROnPlateau(conn=sess, \n",
    "                                 cool_down_iters=2, \n",
    "                                 gamma=0.1, \n",
    "                                 learning_rate=0.01, \n",
    "                                 patience=3\n",
    "                                )\n",
    "\n",
    "# Specify Momentum solver parameters\n",
    "solver = MomentumSolver(lr_scheduler = lr_scheduler,\n",
    "                        clip_grad_max = 100, \n",
    "                        clip_grad_min = -100\n",
    "                       )\n",
    "\n",
    "# Specify optimizer settings\n",
    "optimizer = Optimizer(algorithm=solver, \n",
    "                      mini_batch_size=16, \n",
    "                      log_level=3, \n",
    "                      max_epochs=50, \n",
    "                      reg_l2=0.0005\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Inputs=_image_ is used\n",
      "NOTE: Training based on existing weights.\n",
      "NOTE: Using your-server.unx.your-company.com: 1 out of 2 available GPU devices.\n",
      "NOTE:  Synchronous mode is enabled.\n",
      "NOTE:  The total number of parameters is 415358.\n",
      "NOTE:  The approximate memory cost is 115.00 MB.\n",
      "NOTE:  Loading weights cost       0.00 (s).\n",
      "NOTE:  Initializing each layer cost       0.92 (s).\n",
      "NOTE:  The total number of threads on each worker is 4.\n",
      "NOTE:  The total mini-batch size per thread on each worker is 16.\n",
      "NOTE:  The maximum mini-batch size across all workers for the synchronous mode is 64.\n",
      "NOTE:  Target variable: _label_\n",
      "NOTE:  Number of levels for the target variable:      2\n",
      "NOTE:  Levels for the target variable:\n",
      "NOTE:  Level      0: Dolphin\n",
      "NOTE:  Level      1: Giraffe\n",
      "NOTE:  Number of input variables:     1\n",
      "NOTE:  Number of numeric input variables:      1\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.005571          0     0.2965     0.84\n",
      "NOTE:      1    64     0.01         0.004481          0     0.2965     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  0          0.01        0.005026          0     0.88\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.004302          0     0.2965     0.05\n",
      "NOTE:      1    64     0.01         0.004377          0     0.2965     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  1          0.01        0.004339          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.005703          0     0.2964     0.05\n",
      "NOTE:      1    64     0.01         0.005776          0     0.2964     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  2          0.01        0.005739          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.003788          0     0.2964     0.05\n",
      "NOTE:      1    64     0.01         0.003646          0     0.2964     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  3          0.01        0.003717          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01          0.00367          0     0.2963     0.05\n",
      "NOTE:      1    64     0.01         0.003552          0     0.2963     0.04\n",
      " . . . \n",
      " . . . \n",
      " . . . \n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  47         1E-8         0.00292          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     1E-8         0.003074          0     0.2952     0.05\n",
      "NOTE:      1    64     1E-8         0.003008          0     0.2952     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  48         1E-8        0.003041          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     1E-8         0.004213          0     0.2952     0.05\n",
      "NOTE:      1    64     1E-8         0.003724          0     0.2952     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  49         1E-8        0.003968          0     0.09\n",
      "NOTE:  The optimization reached the maximum number of epochs.\n",
      "NOTE:  The total time is       5.36 (s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Name</td>\n",
       "      <td>model_6tp7ew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Type</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of Layers</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Input Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of Output Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of Convolutional Layers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Pooling Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Fully Connected Layers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Batch Normalization Layers</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of Residual Layers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of Weight Parameters</td>\n",
       "      <td>414184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Number of Bias Parameters</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total Number of Model Parameters</td>\n",
       "      <td>415358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Approximate Memory Cost for Training (MB)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OptIterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch\">Epoch</th>\n",
       "      <th title=\"LearningRate\">LearningRate</th>\n",
       "      <th title=\"Loss\">Loss</th>\n",
       "      <th title=\"FitError\">FitError</th>\n",
       "      <th title=\"L2Norm\">L2Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.004339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>148</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>149</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(UserID)</td>\n",
       "      <td>Model_6TP7eW_weights</td>\n",
       "      <td>416510</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('Model_6TP7eW_weights', caslib='CASUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 6.93s</span> &#183; <span class=\"cas-user\">user 5.82s</span> &#183; <span class=\"cas-sys\">sys 2.15s</span> &#183; <span class=\"cas-memory\">mem 132MB</span></small></p>"
      ],
      "text/plain": [
       "[ModelInfo]\n",
       "\n",
       "                                         Descr                         Value\n",
       " 0                                  Model Name                  model_6tp7ew\n",
       " 1                                  Model Type  Convolutional Neural Network\n",
       " 2                            Number of Layers                            26\n",
       " 3                      Number of Input Layers                             1\n",
       " 4                     Number of Output Layers                             1\n",
       " 5              Number of Convolutional Layers                            10\n",
       " 6                    Number of Pooling Layers                             1\n",
       " 7            Number of Fully Connected Layers                             0\n",
       " 8        Number of Batch Normalization Layers                             9\n",
       " 9                   Number of Residual Layers                             4\n",
       " 10                Number of Weight Parameters                        414184\n",
       " 11                  Number of Bias Parameters                          1174\n",
       " 12           Total Number of Model Parameters                        415358\n",
       " 13  Approximate Memory Cost for Training (MB)                           115\n",
       "\n",
       "[OptIterHistory]\n",
       "\n",
       "     Epoch  LearningRate      Loss  FitError    L2Norm\n",
       " 0     101  1.000000e-02  0.005026       0.0  0.296494\n",
       " 1     102  1.000000e-02  0.004339       0.0  0.296473\n",
       " 2     103  1.000000e-02  0.005739       0.0  0.296434\n",
       " 3     104  1.000000e-02  0.003717       0.0  0.296381\n",
       " .     .    .             .              .    . \n",
       " .     .    .             .              .    . \n",
       " .     .    .             .              .    . \n",
       " 47    148  1.000000e-08  0.002920       0.0  0.295163\n",
       " 48    149  1.000000e-08  0.003041       0.0  0.295163\n",
       " 49    150  1.000000e-08  0.003968       0.0  0.295162\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                  Name    Rows  Columns  \\\n",
       " 0  CASUSER(UserID)  Model_6TP7eW_weights  416510        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('Model_6TP7eW_weights', caslib='CASUS...  \n",
       "\n",
       "+ Elapsed: 6.93s, user: 5.82s, sys: 2.15s, mem: 132mb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "resnet_like_model.fit(data=my_images, \n",
    "                      n_threads=4, \n",
    "                      record_seed=13309, \n",
    "                      optimizer=optimizer,\n",
    "                      gpu=gpu, \n",
    "                      log_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model `resnet_like_model`, when trained with a `ReduceLROnPlateau` learning rate policy, has a final learning rate of 1.000000e-8, a loss value of 0.003968, and a fit error of 0.0.  By comparision, the same model trained with the `CyclicLR` learning rate policy has a final learning rate of 0.005103, a loss value of 0.006719, and a fit error of 0.0.  The same model trained with the `StepLR` learning rate policy had a final learning rate of 1.0 e-28, a loss value of 0.729267, and a fit error of 0.492188.\n",
    "\n",
    "When you compare the fit and error statistics, the model that was trained using the `ReduceLROnPlateau` learning rate policy outperforms the models that were trained using the `CyclicLR` and `StepLR` learning rate policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CustomLR\"></a>\n",
    "\n",
    "#### Specify Customized Learning Rate Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAS DLPy API also provides a flexible approach to defining your own version of a learning rate policy. DLPy enables you to use the SAS FCMP function compiler to create your own custom learning rate policies.\n",
    "\n",
    "The following SAS function compiler code creates a custom learning rate policy called `reduce_lr_on_plateau`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00367s</span> &#183; <span class=\"cas-user\">user 0.00365s</span> &#183; <span class=\"cas-memory\">mem 3.34MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.00367s, user: 0.00365s, mem: 3.34mb"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cool_down_iters = 5\n",
    "patience = 1\n",
    "sess.addRoutines(\n",
    "            routineCode = '''\n",
    "                        function reduce_lr_on_plateau(rate, initRate, gamma, loss[*]);\n",
    "                            len = dim(loss);\n",
    "                            temp_rate = initRate;\n",
    "                            cool_down_counter = {0};\n",
    "                            best = loss[1];\n",
    "                            do i=1 to len;\n",
    "                    \n",
    "                                if loss[i] < best then do;\n",
    "                                    best = loss[i];\n",
    "                                    bad_epoch = 0;\n",
    "                                end;\n",
    "                                else bad_epoch = bad_epoch + 1;\n",
    "                    \n",
    "                                if cool_down_counter > 0 then do;\n",
    "                                    cool_down_counter = cool_down_counter - 1;\n",
    "                                    bad_epoch = 0;\n",
    "                                end;\n",
    "                    \n",
    "                                if bad_epoch > {1} then do;\n",
    "                                    temp_rate = temp_rate * gamma;\n",
    "                                    cool_down_counter = {0};\n",
    "                                    bad_epoch = 0;\n",
    "                                end;\n",
    "                            end;\n",
    "                            rate = temp_rate;\n",
    "                            put rate=;\n",
    "                            return(rate);\n",
    "                        endsub;\n",
    "                        '''.format(cool_down_iters, patience),\n",
    "            package = 'pkg',\n",
    "            funcTable = dict(name = 'reduce_lr_on_plateau', replace = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You custom FCMP function can be called by invoking the FCMP function name while setting `fcmp_learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following argument(s) learning_rate, gamma, step_size, power are overwritten by the according arguments specified in lr_scheduler.\n"
     ]
    }
   ],
   "source": [
    "# Specify the custom LR function \n",
    "# and settings in 'fcmp_learning_rate'\n",
    "lr_scheduler = FCMPLR(conn=sess, \n",
    "                      fcmp_learning_rate='reduce_lr_on_plateau',\n",
    "                      learning_rate = 0.01, \n",
    "                      gamma = 0.1\n",
    "                     )\n",
    "\n",
    "# Specify Momentum solver settings\n",
    "solver = MomentumSolver(lr_scheduler = lr_scheduler,\n",
    "                        clip_grad_max = 100, \n",
    "                        clip_grad_min = -100\n",
    "                       )\n",
    "\n",
    "# Specify optimizer settings\n",
    "optimizer = Optimizer(algorithm=solver, \n",
    "                      mini_batch_size=16, \n",
    "                      log_level=3, \n",
    "                      max_epochs=50, \n",
    "                      reg_l2=0.0005\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Inputs=_image_ is used\n",
      "NOTE: Training based on existing weights.\n",
      "NOTE: Using your-server.unx.your-company.com: 1 out of 2 available GPU devices.\n",
      "NOTE:  Synchronous mode is enabled.\n",
      "NOTE:  The total number of parameters is 415358.\n",
      "NOTE:  The approximate memory cost is 115.00 MB.\n",
      "NOTE:  Loading weights cost       0.00 (s).\n",
      "NOTE:  Initializing each layer cost       0.97 (s).\n",
      "NOTE:  The total number of threads on each worker is 4.\n",
      "NOTE:  The total mini-batch size per thread on each worker is 16.\n",
      "NOTE:  The maximum mini-batch size across all workers for the synchronous mode is 64.\n",
      "NOTE:  Target variable: _label_\n",
      "NOTE:  Number of levels for the target variable:      2\n",
      "NOTE:  Levels for the target variable:\n",
      "NOTE:  Level      0: Dolphin\n",
      "NOTE:  Level      1: Giraffe\n",
      "NOTE:  Number of input variables:     1\n",
      "NOTE:  Number of numeric input variables:      1\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.003794          0     0.2952     0.84\n",
      "NOTE:      1    64     0.01         0.003104          0     0.2952     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  0          0.01        0.003449          0     0.89\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.003031          0     0.2951     0.05\n",
      "NOTE:      1    64     0.01         0.003088          0     0.2951     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  1          0.01         0.00306          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.003532          0     0.2951     0.05\n",
      "NOTE:      1    64     0.01         0.003728          0     0.2951     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  2          0.01         0.00363          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.002714          0     0.2951     0.05\n",
      "NOTE:      1    64     0.01         0.002619          0      0.295     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  3          0.01        0.002667          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     0.01         0.002656          0      0.295     0.05\n",
      "NOTE:      1    64     0.01          0.00257          0      0.295     0.04\n",
      " . . .\n",
      " . . .\n",
      " . . .\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  47         1E-8        0.002483          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     1E-8         0.002598          0     0.2943     0.05\n",
      "NOTE:      1    64     1E-8         0.002556          0     0.2943     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  48         1E-8        0.002577          0     0.09\n",
      "NOTE:  Batch nUsed Learning Rate        Loss  Fit Error     L2Norm   Time(s) (Training)\n",
      "NOTE:      0    64     1E-8         0.003496          0     0.2943     0.05\n",
      "NOTE:      1    64     1E-8          0.00301          0     0.2943     0.04\n",
      "NOTE:  Epoch Learning Rate        Loss  Fit Error   Time(s)\n",
      "NOTE:  49         1E-8        0.003253          0     0.09\n",
      "NOTE:  The optimization reached the maximum number of epochs.\n",
      "NOTE:  The total time is       5.40 (s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; ModelInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Descr\">Descr</th>\n",
       "      <th title=\"Value\">Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model Name</td>\n",
       "      <td>model_6tp7ew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model Type</td>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of Layers</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Input Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number of Output Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Number of Convolutional Layers</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Pooling Layers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Number of Fully Connected Layers</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Number of Batch Normalization Layers</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Number of Residual Layers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Number of Weight Parameters</td>\n",
       "      <td>414184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Number of Bias Parameters</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total Number of Model Parameters</td>\n",
       "      <td>415358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Approximate Memory Cost for Training (MB)</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OptIterHistory</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Epoch\">Epoch</th>\n",
       "      <th title=\"LearningRate\">LearningRate</th>\n",
       "      <th title=\"Loss\">Loss</th>\n",
       "      <th title=\"FitError\">FitError</th>\n",
       "      <th title=\"L2Norm\">L2Norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>198</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>199</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>200</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; OutputCasTables</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"CAS Library\">casLib</th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Number of Rows\">Rows</th>\n",
       "      <th title=\"Number of Columns\">Columns</th>\n",
       "      <th title=\"Table\">casTable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUSER(UserID)</td>\n",
       "      <td>Model_6TP7eW_weights</td>\n",
       "      <td>416510</td>\n",
       "      <td>3</td>\n",
       "      <td>CASTable('Model_6TP7eW_weights', caslib='CASUS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 7.03s</span> &#183; <span class=\"cas-user\">user 5.98s</span> &#183; <span class=\"cas-sys\">sys 2.23s</span> &#183; <span class=\"cas-memory\">mem 132MB</span></small></p>"
      ],
      "text/plain": [
       "[ModelInfo]\n",
       "\n",
       "                                         Descr                         Value\n",
       " 0                                  Model Name                  model_6tp7ew\n",
       " 1                                  Model Type  Convolutional Neural Network\n",
       " 2                            Number of Layers                            26\n",
       " 3                      Number of Input Layers                             1\n",
       " 4                     Number of Output Layers                             1\n",
       " 5              Number of Convolutional Layers                            10\n",
       " 6                    Number of Pooling Layers                             1\n",
       " 7            Number of Fully Connected Layers                             0\n",
       " 8        Number of Batch Normalization Layers                             9\n",
       " 9                   Number of Residual Layers                             4\n",
       " 10                Number of Weight Parameters                        414184\n",
       " 11                  Number of Bias Parameters                          1174\n",
       " 12           Total Number of Model Parameters                        415358\n",
       " 13  Approximate Memory Cost for Training (MB)                           115\n",
       "\n",
       "[OptIterHistory]\n",
       "\n",
       "     Epoch  LearningRate      Loss  FitError    L2Norm\n",
       " 0     151  1.000000e-02  0.003449       0.0  0.295160\n",
       " 1     152  1.000000e-02  0.003060       0.0  0.295138\n",
       " 2     153  1.000000e-02  0.003630       0.0  0.295099\n",
       " 3     154  1.000000e-02  0.002667       0.0  0.295046\n",
       " 4     155  1.000000e-02  0.002613       0.0  0.294981\n",
       " 5     156  1.000000e-02  0.002626       0.0  0.294906\n",
       " 6     157  1.000000e-02  0.002626       0.0  0.294824\n",
       " 7     158  1.000000e-03  0.002712       0.0  0.294738\n",
       " 8     159  1.000000e-03  0.003155       0.0  0.294665\n",
       " 9     160  1.000000e-03  0.002797       0.0  0.294603\n",
       " 10    161  1.000000e-03  0.002894       0.0  0.294550\n",
       " 11    162  1.000000e-03  0.002522       0.0  0.294506\n",
       " 12    163  1.000000e-03  0.002441       0.0  0.294467\n",
       " 13    164  1.000000e-03  0.002548       0.0  0.294434\n",
       " 14    165  1.000000e-03  0.002612       0.0  0.294405\n",
       " 15    166  1.000000e-04  0.002851       0.0  0.294379\n",
       " 16    167  1.000000e-04  0.002570       0.0  0.294358\n",
       " 17    168  1.000000e-04  0.004145       0.0  0.294341\n",
       " 18    169  1.000000e-04  0.002423       0.0  0.294327\n",
       " 19    170  1.000000e-04  0.007741       0.0  0.294315\n",
       " 20    171  1.000000e-04  0.002360       0.0  0.294305\n",
       " 21    172  1.000000e-04  0.002583       0.0  0.294297\n",
       " 22    173  1.000000e-04  0.002458       0.0  0.294290\n",
       " 23    174  1.000000e-05  0.002476       0.0  0.294285\n",
       " 24    175  1.000000e-05  0.002352       0.0  0.294280\n",
       " 25    176  1.000000e-05  0.002434       0.0  0.294276\n",
       " 26    177  1.000000e-05  0.002501       0.0  0.294273\n",
       " 27    178  1.000000e-05  0.002998       0.0  0.294271\n",
       " 28    179  1.000000e-05  0.002530       0.0  0.294269\n",
       " 29    180  1.000000e-05  0.002571       0.0  0.294267\n",
       " 30    181  1.000000e-06  0.002446       0.0  0.294266\n",
       " 31    182  1.000000e-06  0.002536       0.0  0.294264\n",
       " 32    183  1.000000e-06  0.002946       0.0  0.294264\n",
       " 33    184  1.000000e-06  0.002509       0.0  0.294263\n",
       " 34    185  1.000000e-06  0.002589       0.0  0.294262\n",
       " 35    186  1.000000e-06  0.002766       0.0  0.294262\n",
       " 36    187  1.000000e-06  0.002992       0.0  0.294261\n",
       " 37    188  1.000000e-07  0.002557       0.0  0.294261\n",
       " 38    189  1.000000e-07  0.002747       0.0  0.294261\n",
       " 39    190  1.000000e-07  0.002990       0.0  0.294261\n",
       " 40    191  1.000000e-07  0.002590       0.0  0.294260\n",
       " 41    192  1.000000e-07  0.002601       0.0  0.294260\n",
       " 42    193  1.000000e-07  0.002531       0.0  0.294260\n",
       " 43    194  1.000000e-07  0.002724       0.0  0.294260\n",
       " 44    195  1.000000e-08  0.002528       0.0  0.294260\n",
       " 45    196  1.000000e-08  0.002596       0.0  0.294260\n",
       " 46    197  1.000000e-08  0.002387       0.0  0.294260\n",
       " 47    198  1.000000e-08  0.002483       0.0  0.294260\n",
       " 48    199  1.000000e-08  0.002577       0.0  0.294260\n",
       " 49    200  1.000000e-08  0.003253       0.0  0.294260\n",
       "\n",
       "[OutputCasTables]\n",
       "\n",
       "             casLib                  Name    Rows  Columns  \\\n",
       " 0  CASUSER(UserID)  Model_6TP7eW_weights  416510        3   \n",
       " \n",
       "                                             casTable  \n",
       " 0  CASTable('Model_6TP7eW_weights', caslib='CASUS...  \n",
       "\n",
       "+ Elapsed: 7.03s, user: 5.98s, sys: 2.23s, mem: 132mb"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the custom\n",
    "# FCMP learning rate settings\n",
    "resnet_like_model.fit(data=my_images, \n",
    "                      n_threads=4, \n",
    "                      record_seed=13309, \n",
    "                      optimizer=optimizer,\n",
    "                      gpu=gpu, \n",
    "                      log_level=2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model `resnet_like_model`, when trained with a custom-written SAS FCMP function `reduce_lr_on_plateau` learning rate policy, has a final learning rate of 1.00e-08, a loss value of 0.003253, and a fit error of 0.00.  \n",
    "\n",
    "By comparison:\n",
    "\n",
    "- The same model trained with the `ReduceLROnPlateau` learning rate policy has a final learning rate of 1.000000e-8, a loss value of 0.003968, and a fit error of 0.00. \n",
    "- The same model trained with the `CyclicLR` learning rate policy has a final learning rate of 0.005103, a loss value of 0.006719, and a fit error of 0.0. \n",
    "- The same model trained with the `StepLR` learning rate policy has a final learning rate of 1.00e-28, a loss value of 0.729267, and a fit error of 0.492188.\n",
    "\n",
    "When you compare the fit and error statistics, the model that was trained using the custom-written SAS FCMP function `reduce_lr_on_plateau` learning rate policy outperforms the models that were trained using the `ReduceLROnPlateau`, `CyclicLR`, and `StepLR` learning rate policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.endsession()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
